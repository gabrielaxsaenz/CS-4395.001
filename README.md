# CS-4395.001
 This is the repository for my Human Language Technologies class portfolio. Created Fall2022
 
# Assignment 0
 This [assignment](Overview-of-NLP.pdf) allowed me to review historical and modern approaches to NLP while reflecting on what I will be learning in this course.
# Assignment 1
 In [this assignment](Homework1_gvs180000.py), I worked on a program that managed employee data from an obselete file. 
 The problem can be run in the terminal with the command "python3 Homework1_gvs180000.py data/data.csv" 
  Note: the filepath "data/data.csv" may be different on your local machine, but the .csv file MUST be located in the same file as the .py file
 By completing this assignment in python, I was able to use the text processing tools and functions that python has to offer.
 For example, Python has a very intuitive process for identifying variables, making it easy to move between different types of variables such as lists or strings.
 In addition, Python is good for text processing because the dictionary data structure keeps objects well organized.
 Throughout this assignment I learned that Python offers easy to learn and use syntax and structure to its language. Also, I learned how to simplify the functions I use
 when processing text to make a more efficient program.
 
# Assignment 2
  In [assignment 2](Assignment2_gvs180000.ipynb%20-%20Colaboratory.pdf) I worked in Google Colab to demonstrate use of NLTK.

# Word Guess Game
 This [program](WordGuessGame) showcases a game where players have the chance to guess the individual letters of a word, with blank spaces representing each, until they correctly guess the whole word. During this project I learned to use pos tagging and lexical diversity calculations to analyze tokens from texts.
 
# WordNet
 In [this program](gvs180000-Portfolio-WordNet-Colaboratory.pdf) I learned to use WordNet and SentiWordNet to determine connections between words, as well as identify collocations.

# Ngrams
 This [project](Ngrams) helped me learn to create unigrams and bigrams of texts. Then, I used english, french, and italian texts of training data to create dictionaries for each unigram or bigrams where they are the key and their count is the value. The dictionaries were then used to build language models to predicts the probabilities of a sentence being each of the 3 languages. 
 
# WebCrawler
This [assignment](WebCrawler) taught me about different APIs and techniques used to scrape data off of web pages. The data collected from web pages can target a certain topic and then be used to build a corpora, knowledge base, and even a chat bot.
